# ğŸ–¼ï¸ Image Q&A with LLaVA (Local Ollama + Streamlit)

A simple, fully local web application that lets you **upload an image**, display it instantly, and then **ask questions about it using natural language**.  
Powered by **Ollama** running the **LLaVA vision-language model** locally â€” no cloud, no API keys, fully private.

This app provides:
- ğŸ–¼ï¸ Image upload & display  
- ğŸ’¬ Chat window with persistent history  
- ğŸ¤– Visual question answering using LLaVA  
- ğŸ” 100% local inference (Ollama)  
- âš¡ Fast, lightweight and easy to run  

---

## ğŸš€ Features

### âœ” Upload an Image  
Drag & drop or browse any `.png`, `.jpg`, or `.jpeg`.

### âœ” Ask Questions About the Image  
The model can answer things like:
- â€œWhat objects are in this room?â€
- â€œDescribe the setting.â€
- â€œIs this a kitchen or living room?â€
- â€œWhat colors dominate the scene?â€

### âœ” Full Chat Memory  
Your messages and the AI replies stay visible on the page.

### âœ” Local Vision LLM (LLaVA)  
Runs locally via **Ollama**, ensuring:
- No data leaves your device  
- Faster inference  
- Works offline  

## ğŸ›  Requirements

### 1. Install Python packages
pip install streamlit pillow

### 2. Install Ollama (if not installed)
Download for Windows, macOS, or Linux:
https://ollama.com/


### Pull the LLaVA model
ollama pull llava

## â–¶ï¸ Running the App
streamlit run VisionLLM_Image.py

